@Techreport{CISCO2019,
	author = "Cisco",
	title = "{Cisco Visual Networking Index: Global Mobile Data Traffic Forecast Update, 2017-2022}",
	year = 2019,
}

@techreport{ISO/IEC23009-1:2019,
	type = {Standard},
	title = {Information technology — Dynamic adaptive streaming over HTTP (DASH) — Part 1: Media presentation description and segment formats},
	shorttitle = {{ISO}/{IEC} 23009-1:2019},
	url = {https://www.iso.org/standard/79329.html},
	language = {en},
	number = {ISO/IEC 23009-1:2019},
	institution = {International Organization for Standardization},
	author = {{ISO Central Secretary}},
	year = {2016}
}

@inproceedings{10.5555/1402298.1402344,
	author = {de Jong, Steven and Tuyls, Karl and Verbeeck, Katja},
	title = {Artificial Agents Learning Human Fairness},
	year = {2008},
	isbn = {9780981738116},
	publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
	address = {Richland, SC},
	abstract = {Recent advances in technology allow multi-agent systems to be deployed in cooperation with or as a service for humans. Typically, those systems are designed assuming individually rational agents, according to the principles of classical game theory. However, research in the field of behavioral economics has shown that humans are not purely self-interested: they strongly care about fairness. Therefore, multi-agent systems that fail to take fairness into account, may not be sufficiently aligned with human expectations and may not reach intended goals. In this paper, we present a computational model for achieving fairness in adaptive multi-agent systems. The model uses a combination of Continuous Action Learning Automata and the Homo Egualis utility function. The novel contribution of our work is that this function is used in an explicit, computational manner. We show that results obtained by agents using this model are compatible with experimental and analytical results on human fairness, obtained in the field of behavioral economics.},
	booktitle = {Proceedings of the 7th International Joint Conference on Autonomous Agents and Multiagent Systems - Volume 2},
	pages = {863–870},
	numpages = {8},
	keywords = {fairness, reinforcement learning, homo egualis},
	location = {Estoril, Portugal},
	series = {AAMAS '08}
}

@book{P-1066,
	author="Bellman, Richard",
	title="A Markovian decision process.",
	year="1957",
	doi="",
	publisher="Technical report, DTIC Document"
}

@article{sutton1999policy,
	title={Policy gradient methods for reinforcement learning with function approximation},
	author={Sutton, Richard S and McAllester, David and Singh, Satinder and Mansour, Yishay},
	journal={Advances in neural information processing systems},
	volume={12},
	pages={1057--1063},
	year={1999}
}

@inproceedings{10.5555/3045390.3045594,
	author = {Mnih, Volodymyr and Badia, Adri\`{a} Puigdom\`{e}nech and Mirza, Mehdi and Graves, Alex and Harley, Tim and Lillicrap, Timothy P. and Silver, David and Kavukcuoglu, Koray},
	title = {Asynchronous Methods for Deep Reinforcement Learning},
	year = {2016},
	publisher = {JMLR.org},
	abstract = {We propose a conceptually simple and lightweight framework for deep reinforcement learning that uses asynchronous gradient descent for optimization of deep neural network controllers. We present asynchronous variants of four standard reinforcement learning algorithms and show that parallel actor-learners have a stabilizing effect on training allowing all four methods to successfully train neural network controllers. The best performing method, an asynchronous variant of actor-critic, surpasses the current state-of-the-art on the Atari domain while training for half the time on a single multi-core CPU instead of a GPU. Furthermore, we show that asynchronous actor-critic succeeds on a wide variety of continuous motor control problems as well as on a new task of navigating random 3D mazes using a visual input.},
	booktitle = {Proceedings of the 33rd International Conference on International Conference on Machine Learning - Volume 48},
	pages = {1928–1937},
	numpages = {10},
	location = {New York, NY, USA},
	series = {ICML'16}
}



